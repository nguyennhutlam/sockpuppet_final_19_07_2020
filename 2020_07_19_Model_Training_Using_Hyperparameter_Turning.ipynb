{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020_07_19_Model_Training_Using_Hyperparameter_Turning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOXCpLAn+0BfIsOC9oKL2mo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyennhutlam/sockpuppet_final_19_07_2020/blob/master/2020_07_19_Model_Training_Using_Hyperparameter_Turning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZJY_sASbAaV",
        "colab_type": "text"
      },
      "source": [
        "# Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY0Pu_SPbDfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "# ignore warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# ML library\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import  VotingClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import  KFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import statistics\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import random\n",
        "from numpy.random import seed\n",
        "# evaluation metrics\n",
        "scoring = {'accuracy': 'accuracy', 'recall': 'recall', 'precision': 'precision', 'f1':'f1', 'roc_auc': 'roc_auc'}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5NB0T31bQes",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgrexWgzbUWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function is used for undersampling\n",
        "# paramters: \n",
        "#   data: dataset\n",
        "#   ration: ratio between minority class and mojority class       \n",
        "def undersampling(data, ratio):\n",
        "  B1_class_len = len(data[data['class'] == 0]) #lenght of the minority class (B1: sockpuppet accounts) #163\n",
        "  legitimate_indices = data[data['class'] == 1].index\n",
        "  random_legitimate_indices = np.random.choice(legitimate_indices, B1_class_len * ratio, replace = True)\n",
        "  B1_class_indices = data[data['class'] == 0].index\n",
        "  under_sampe_indices = np.concatenate([B1_class_indices, random_legitimate_indices])\n",
        "  under_sample = data.loc[under_sampe_indices]\n",
        "  return under_sample #return the undersampled dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJPGuQbEcaYk",
        "colab_type": "text"
      },
      "source": [
        "Training a model using cross validation \\\\\n",
        "model: ML classifier \\\\\n",
        "fold: #fold for cross validate \\\\\n",
        "X, y : training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enm9J_s_btG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cross_val(model,label, fold, X, y):\n",
        "    cv = KFold(n_splits=fold, shuffle=True, random_state=1)\n",
        "    decimal = 3\n",
        "    acc = []\n",
        "    pre = []\n",
        "    rec = []\n",
        "    f1s = []\n",
        "    auc = []\n",
        "    df_pred = pd.DataFrame() # dataframe stores the prediction for each sample\n",
        "    df_pred_prob = pd.DataFrame() # dataframe stores the predict probability for each sample\n",
        "    cf_matrix = np.zeros((2,2))\n",
        "    for train, test in (cv.split(X, y)):\n",
        "      model.fit(X[train], y[train])\n",
        "\n",
        "      pred = model.predict(X[test])\n",
        "\n",
        "      #output dataframe of predict values\n",
        "      df_pred_temp = pd.DataFrame(list(zip(pred)), index=test, columns=[label+'_y_pred'])\n",
        "      df_pred = pd.concat([df_pred, df_pred_temp])\n",
        "      \n",
        "      #output dataframe of predict probability values\n",
        "      pred_pro = model.predict_proba(X[test])\n",
        "      df_pred_prob_temp = pd.DataFrame(list(zip(pred_pro[:,0])), index=test, columns=[label+'_y_pred_0'])\n",
        "      df_pred_prob = pd.concat([df_pred_prob, df_pred_prob_temp])\n",
        "\n",
        "      acc.append(accuracy_score(y[test], pred))\n",
        "      pre.append(precision_score(y[test], pred))\n",
        "      rec.append(recall_score(y[test], pred))\n",
        "      f1s.append(f1_score(y[test], pred))\n",
        "      auc.append(roc_auc_score(y[test], pred_pro[:,1]))\n",
        "      cf_matrix += (confusion_matrix(y[test], pred))\n",
        "\n",
        "    acc = np.round(np.mean(acc), decimal)\n",
        "    pre = np.round(np.mean(pre), decimal)\n",
        "    rec = np.round(np.mean(rec), decimal)\n",
        "    f1s = np.round(np.mean(f1s), decimal)\n",
        "    auc = np.round(np.mean(auc), decimal)\n",
        "    return (acc, pre, rec, f1s, auc, cf_matrix , df_pred, df_pred_prob)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B_kCVEpmex0",
        "colab_type": "text"
      },
      "source": [
        "Train individual model using cross validation for all datasets (10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2huIw_dmml7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_each_model_all_dataset(clf, lbl):\n",
        "  cols = ['classifier','accuracy','precision','recall','f1_score', 'roc_auc']\n",
        "  result = pd.DataFrame(columns=cols)\n",
        "  for i in range(10):\n",
        "    #print(i)\n",
        "    df = dataset[str(i)].copy()\n",
        "    df = df.reset_index(drop=True) # reset dataframe index\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "    X = scaler.fit_transform(X)\n",
        "    (acc, pre, rec, f1s, auc, cf_matrix , pred, prob) = train_cross_val(clf, lbl , fold, X, y)\n",
        "    result.loc[len(result)] = [lbl, acc,pre, rec, f1s, auc] #add evaluate metrics\n",
        "  return (result, (result.mean()).round(3), (result.std()).round(3))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPc9Y86Jbto3",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU600QF7b7gw",
        "colab_type": "text"
      },
      "source": [
        "Read full dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARIPTLq2bz64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f7910750-9aab-46d6-8834-8fc71cd0e4f8"
      },
      "source": [
        "file =\"https://raw.githubusercontent.com/nguyennhutlam/sockpuppet_dataset/master/Feature_29_final.csv\"\n",
        "data = pd.read_csv(file)\n",
        "data.type.replace(['Sockpuppet','Legitimate_user'], [0, 1], inplace = True)\n",
        "data = data.drop(columns=['id']) #remove id column\n",
        "data['class'] = data['type']\n",
        "data = data.drop(columns=['type']) #remove type columns\n",
        "#sns.countplot(x='class', data=data)\n",
        "# number of instances in each class\n",
        "data['class'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    106230\n",
              "0      1668\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwofxfGgb_UT",
        "colab_type": "text"
      },
      "source": [
        "Generate 10 Dataset using undersampling for training, store in dictinary\n",
        "*dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh06KRnqb6G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "dataset = {} # dictionary of dataframe\n",
        "for i in range(10):\n",
        "    random.seed(i)\n",
        "    dataset[str(i)] = undersampling(data,1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzTy-nmPc5_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CnM0iyDc6Y6",
        "colab_type": "text"
      },
      "source": [
        "# Traing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4mySMYwdTAS",
        "colab_type": "text"
      },
      "source": [
        "Define the list of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkDVEjPyc8xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = []\n",
        "model.append(('NB',GaussianNB(var_smoothing=1e-05)))\n",
        "model.append(('kNN', KNeighborsClassifier(n_neighbors=15, weights='distance', algorithm='ball_tree')))\n",
        "model.append(('SVM', SVC(probability=True, C=100, kernel='rbf')))\n",
        "model.append(('RF', RandomForestClassifier(criterion='entropy', max_features=3, n_estimators= 200)))\n",
        "model.append(('Ada', AdaBoostClassifier(RandomForestClassifier(criterion='entropy', max_features=3, n_estimators= 200), learning_rate=0.3, n_estimators=100)))\n",
        "model.append(('XGB', XGBClassifier(colsample_bytree=0.7, gamma=1.5, max_depth=10, min_child_weight=5)))\n",
        "\n",
        "fold = 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIOvOP8rnJJM",
        "colab_type": "text"
      },
      "source": [
        "Result for each model for all datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv_fLppFoUz6",
        "colab_type": "text"
      },
      "source": [
        "0 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651FvJapnM67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "6ab43a2c-090c-46da-b1e1-1029103f15ad"
      },
      "source": [
        "seed(1)\n",
        "m = 0 #NB\n",
        "clf = model[m][1]\n",
        "lbl = model[m][0]\n",
        "result, pred, prob = train_each_model_all_dataset(clf, lbl)\n",
        "print(result)\n",
        "print(pred)\n",
        "print(prob)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifier  accuracy  precision  recall  f1_score  roc_auc\n",
            "0         NB     0.618      0.575   0.915     0.705    0.748\n",
            "1         NB     0.607      0.565   0.939     0.705    0.741\n",
            "2         NB     0.638      0.591   0.902     0.713    0.746\n",
            "3         NB     0.655      0.603   0.908     0.724    0.754\n",
            "4         NB     0.596      0.557   0.939     0.699    0.732\n",
            "5         NB     0.624      0.582   0.890     0.703    0.736\n",
            "6         NB     0.614      0.571   0.923     0.705    0.750\n",
            "7         NB     0.605      0.562   0.949     0.706    0.748\n",
            "8         NB     0.608      0.565   0.947     0.707    0.746\n",
            "9         NB     0.607      0.566   0.926     0.702    0.744\n",
            "accuracy     0.617\n",
            "precision    0.574\n",
            "recall       0.924\n",
            "f1_score     0.707\n",
            "roc_auc      0.744\n",
            "dtype: float64\n",
            "accuracy     0.018\n",
            "precision    0.014\n",
            "recall       0.020\n",
            "f1_score     0.007\n",
            "roc_auc      0.007\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyvjuDCsoZGd",
        "colab_type": "text"
      },
      "source": [
        "1 KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQY6V1VYfZU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "08985f71-e065-4b53-f7fb-3aa5a4f9ece3"
      },
      "source": [
        "seed(1)\n",
        "m = 1 # KNN\n",
        "clf = model[m][1]\n",
        "lbl = model[m][0]\n",
        "result, pred, prob = train_each_model_all_dataset(clf, lbl)\n",
        "print(result)\n",
        "print(pred)\n",
        "print(prob)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifier  accuracy  precision  recall  f1_score  roc_auc\n",
            "0        kNN     0.743      0.745   0.740     0.742    0.813\n",
            "1        kNN     0.740      0.736   0.750     0.742    0.816\n",
            "2        kNN     0.727      0.724   0.735     0.729    0.800\n",
            "3        kNN     0.742      0.744   0.740     0.741    0.811\n",
            "4        kNN     0.740      0.744   0.733     0.738    0.813\n",
            "5        kNN     0.737      0.745   0.723     0.733    0.808\n",
            "6        kNN     0.751      0.756   0.743     0.749    0.812\n",
            "7        kNN     0.751      0.757   0.742     0.748    0.818\n",
            "8        kNN     0.749      0.744   0.761     0.751    0.821\n",
            "9        kNN     0.748      0.743   0.760     0.751    0.817\n",
            "accuracy     0.743\n",
            "precision    0.744\n",
            "recall       0.743\n",
            "f1_score     0.742\n",
            "roc_auc      0.813\n",
            "dtype: float64\n",
            "accuracy     0.007\n",
            "precision    0.009\n",
            "recall       0.012\n",
            "f1_score     0.008\n",
            "roc_auc      0.006\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1x1X-Dtorum",
        "colab_type": "text"
      },
      "source": [
        "2 SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on0lc4zsoTvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ad0162de-cfb5-4f4d-abd7-eb0925d41ace"
      },
      "source": [
        "seed(1)\n",
        "m = 2 # SVM\n",
        "clf = model[m][1]\n",
        "lbl = model[m][0]\n",
        "result, pred, prob = train_each_model_all_dataset(clf, lbl)\n",
        "print(result)\n",
        "print(pred)\n",
        "print(prob)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifier  accuracy  precision  recall  f1_score  roc_auc\n",
            "0        SVM     0.761      0.733   0.823     0.774    0.824\n",
            "1        SVM     0.775      0.750   0.826     0.785    0.837\n",
            "2        SVM     0.754      0.725   0.818     0.768    0.814\n",
            "3        SVM     0.769      0.746   0.818     0.779    0.832\n",
            "4        SVM     0.770      0.755   0.801     0.776    0.838\n",
            "5        SVM     0.761      0.747   0.790     0.767    0.830\n",
            "6        SVM     0.763      0.743   0.806     0.772    0.821\n",
            "7        SVM     0.775      0.758   0.805     0.780    0.837\n",
            "8        SVM     0.775      0.750   0.826     0.786    0.845\n",
            "9        SVM     0.768      0.743   0.823     0.780    0.838\n",
            "accuracy     0.767\n",
            "precision    0.745\n",
            "recall       0.814\n",
            "f1_score     0.777\n",
            "roc_auc      0.832\n",
            "dtype: float64\n",
            "accuracy     0.007\n",
            "precision    0.010\n",
            "recall       0.012\n",
            "f1_score     0.007\n",
            "roc_auc      0.009\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBit5lJirddf",
        "colab_type": "text"
      },
      "source": [
        "3 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBE0I6v5rctx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "1f621e42-b45d-4fa9-9cc0-f5dd0a053973"
      },
      "source": [
        "seed(1)\n",
        "m = 3 #Random Forest\n",
        "clf = model[m][1]\n",
        "lbl = model[m][0]\n",
        "result, pred, prob = train_each_model_all_dataset(clf, lbl)\n",
        "print(result)\n",
        "print(pred)\n",
        "print(prob)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifier  accuracy  precision  recall  f1_score  roc_auc\n",
            "0         RF     0.814      0.812   0.816     0.813    0.884\n",
            "1         RF     0.819      0.809   0.833     0.820    0.885\n",
            "2         RF     0.807      0.799   0.821     0.810    0.881\n",
            "3         RF     0.809      0.807   0.812     0.809    0.885\n",
            "4         RF     0.812      0.810   0.815     0.812    0.888\n",
            "5         RF     0.801      0.805   0.794     0.799    0.880\n",
            "6         RF     0.803      0.797   0.815     0.805    0.884\n",
            "7         RF     0.825      0.814   0.842     0.827    0.891\n",
            "8         RF     0.822      0.812   0.838     0.824    0.888\n",
            "9         RF     0.821      0.816   0.831     0.823    0.885\n",
            "accuracy     0.813\n",
            "precision    0.808\n",
            "recall       0.822\n",
            "f1_score     0.814\n",
            "roc_auc      0.885\n",
            "dtype: float64\n",
            "accuracy     0.008\n",
            "precision    0.006\n",
            "recall       0.014\n",
            "f1_score     0.009\n",
            "roc_auc      0.003\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSqT_qBlrtRN",
        "colab_type": "text"
      },
      "source": [
        "4 AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giXJyhgLryl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "8894ad90-2f83-4d47-f66e-05fc6d8a1b9e"
      },
      "source": [
        "seed(1)\n",
        "m = 4 #AdaBoost\n",
        "clf = model[m][1]\n",
        "lbl = model[m][0]\n",
        "result, pred, prob = train_each_model_all_dataset(clf, lbl)\n",
        "print(result)\n",
        "print(pred)\n",
        "print(prob)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifier  accuracy  precision  recall  f1_score  roc_auc\n",
            "0        Ada     0.811      0.812   0.809     0.810    0.884\n",
            "1        Ada     0.819      0.813   0.827     0.819    0.886\n",
            "2        Ada     0.814      0.805   0.828     0.816    0.882\n",
            "3        Ada     0.811      0.810   0.812     0.811    0.884\n",
            "4        Ada     0.807      0.803   0.815     0.808    0.886\n",
            "5        Ada     0.803      0.807   0.796     0.801    0.878\n",
            "6        Ada     0.801      0.795   0.811     0.802    0.883\n",
            "7        Ada     0.823      0.814   0.839     0.826    0.891\n",
            "8        Ada     0.821      0.813   0.836     0.824    0.887\n",
            "9        Ada     0.824      0.818   0.833     0.825    0.886\n",
            "accuracy     0.813\n",
            "precision    0.809\n",
            "recall       0.821\n",
            "f1_score     0.814\n",
            "roc_auc      0.885\n",
            "dtype: float64\n",
            "accuracy     0.008\n",
            "precision    0.007\n",
            "recall       0.014\n",
            "f1_score     0.009\n",
            "roc_auc      0.003\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXyoYmPLr3oT",
        "colab_type": "text"
      },
      "source": [
        "5 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixx6P5ASr5gL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4e9135fb-c8ac-40b8-8589-7688089404c4"
      },
      "source": [
        "seed(1)\n",
        "m = 5 #XGBoost\n",
        "clf = model[m][1]\n",
        "lbl = model[m][0]\n",
        "result, pred, prob = train_each_model_all_dataset(clf, lbl)\n",
        "print(result)\n",
        "print(pred)\n",
        "print(prob)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  classifier  accuracy  precision  recall  f1_score  roc_auc\n",
            "0        XGB     0.823      0.816   0.835     0.825    0.895\n",
            "1        XGB     0.814      0.805   0.827     0.816    0.892\n",
            "2        XGB     0.820      0.805   0.844     0.823    0.889\n",
            "3        XGB     0.813      0.805   0.824     0.814    0.890\n",
            "4        XGB     0.822      0.813   0.836     0.824    0.898\n",
            "5        XGB     0.805      0.803   0.808     0.805    0.885\n",
            "6        XGB     0.817      0.809   0.831     0.819    0.892\n",
            "7        XGB     0.831      0.819   0.849     0.833    0.902\n",
            "8        XGB     0.825      0.812   0.845     0.828    0.898\n",
            "9        XGB     0.830      0.821   0.845     0.832    0.897\n",
            "accuracy     0.820\n",
            "precision    0.811\n",
            "recall       0.834\n",
            "f1_score     0.822\n",
            "roc_auc      0.894\n",
            "dtype: float64\n",
            "accuracy     0.008\n",
            "precision    0.006\n",
            "recall       0.012\n",
            "f1_score     0.009\n",
            "roc_auc      0.005\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}